{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    " def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, filter_size, num_input_channels, num_filters, stride=2, padding='VALID'):\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        self.shape = shape\n",
    "        self.W = new_weights(shape)\n",
    "        self.b = new_biases(num_filters)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    def forward(self, X):\n",
    "        X = tf.nn.conv2d(X, self.W, strides=[1, self.stride, self.stride, 1], padding=self.padding)\n",
    "        return X + self.b\n",
    "    \n",
    "    def get_params(self):\n",
    "        return [self.W, self.b]\n",
    "        \n",
    "    def copyFromKerasLayers(self, layer):\n",
    "        W, b = layer.get_weights()\n",
    "        op1 = self.W.assign(W)\n",
    "        op2 = self.b.assign(b)\n",
    "        self.session.run((op1, op2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormLayer:\n",
    "    def __init__(self, D):\n",
    "        self.mean = tf.Variable(np.zeros(D, dtype=np.float32), trainable=False)\n",
    "        self.var = tf.Variable(np.ones(D, dtype=np.float32), trainable=False)\n",
    "        self.gamma = tf.Variable(np.ones(D, dtype=np.float32))\n",
    "        self.beta = tf.Variable(np.zeros(D, dtype=np.float32))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return tf.nn.batch_normalization(X, self.mean, self.var, self.beta, self.gamma, 1e-3)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return [self.gamma, self.beta, self.mean, self.var]\n",
    "    \n",
    "    def copyFromKerasLayers(self, layer):\n",
    "        gamma, beta, mean, var = layer.get_weights()\n",
    "        op1 = self.mean.assign(mean)\n",
    "        op2 = self.var.assign(var)\n",
    "        op3 = self.gamma.assign(gamma)\n",
    "        op4 = self.beta.assign(beta)\n",
    "        self.session.run((op1, op2, op3, op4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock:\n",
    "    def __init__(self, num_input_channels, feature_map_sizes, stride=2, activation=tf.nn.relu):\n",
    "        self.session = None\n",
    "        self.f = tf.nn.relu\n",
    "        \n",
    "        #main branch: Conv -> BN -> F() -> Conv -> BN -> F() -> Conv -> BN\n",
    "        self.conv1 = ConvLayer(1, num_input_channels, feature_map_sizes[0], stride)\n",
    "        self.bn1 = BatchNormLayer(feature_map_sizes[0])\n",
    "        self.conv2 = ConvLayer(3, feature_map_sizes[0], feature_map_sizes[1], 1, 'SAME')\n",
    "        self.bn2 = BatchNormLayer(feature_map_sizes[1])\n",
    "        self.conv3 = ConvLayer(1, feature_map_sizes[1], feature_map_sizes[2], 1)\n",
    "        self.bn3 = BatchNormLayer(feature_map_sizes[2])\n",
    "        \n",
    "        # shortcut brunch Conv -> BN\n",
    "        self.convs = ConvLayer(1, num_input_channels, feature_map_sizes[2], stride)\n",
    "        self.bns = BatchNormLayer(feature_map_sizes[2])\n",
    "        \n",
    "        self.layers = [self.conv1, self.bn1, self.conv2, self.bn2, self.conv3, self.bn3, self.convs, self.bns]\n",
    "        \n",
    "        self.input_ = tf.placeholder(tf.float32, shape=(1, 224, 224, num_input_channels))\n",
    "        self.output = self.forward(self.input_)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # main branch \n",
    "        FX = self.conv1.forward(X)\n",
    "        FX = self.bn1.forward(FX)\n",
    "        FX = self.f(FX)\n",
    "        FX = self.conv2.forward(FX)\n",
    "        FX = self.bn2.forward(FX)\n",
    "        FX = self.f(FX)\n",
    "        FX = self.conv3.forward(FX)\n",
    "        FX = self.bn3.forward(FX)\n",
    "        #short cut\n",
    "        SX = self.convs.forward(X)\n",
    "        SX = self.bns.forward(SX)\n",
    "        \n",
    "        return self.f(FX + SX)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert(self.session is not None)\n",
    "        return self.session.run(self.output, feed_dict={self.input_: X})\n",
    "    \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        self.conv1.session = session\n",
    "        self.bn1.session = session\n",
    "        self.conv2.session = session\n",
    "        self.bn2.session = session\n",
    "        self.conv3.session = session\n",
    "        self.bn3.session = session\n",
    "        self.convs.session = session\n",
    "        self.bns.session = session\n",
    "    \n",
    "    def copyFromKerasLayers(self, layers):\n",
    "        self.conv1.copyFromKerasLayers(layers[0])\n",
    "        self.bn1.copyFromKerasLayers(layers[1])\n",
    "        self.conv2.copyFromKerasLayers(layers[3])\n",
    "        self.bn2.copyFromKerasLayers(layers[4])\n",
    "        self.conv3.copyFromKerasLayers(layers[6])\n",
    "        self.bn3.copyFromKerasLayers(layers[8])\n",
    "        self.convs.copyFromKerasLayers(layers[7])\n",
    "        self.bns.copyFromKerasLayers(layers[9])\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.get_params()\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBlock:\n",
    "    def __init__(self, num_input_channels, feature_map_sizes, activation=tf.nn.relu):\n",
    "        self.session = None\n",
    "        self.f = tf.nn.relu\n",
    "        \n",
    "        # main branch Conv -> BN -> f() -> Conv -> BN -> F() -> Conv -> BN\n",
    "        self.conv1 = ConvLayer(1, num_input_channels, feature_map_sizes[0], 1)\n",
    "        self.bn1 = BatchNormLayer(feature_map_sizes[0])\n",
    "        self.conv2 = ConvLayer(3, feature_map_sizes[0], feature_map_sizes[1], 1, 'SAME')\n",
    "        self.bn2 = BatchNormLayer(feature_map_sizes[1])\n",
    "        self.conv3 = ConvLayer(1, feature_map_sizes[1], feature_map_sizes[2], 1)\n",
    "        self.bn3 = BatchNormLayer(feature_map_sizes[2])\n",
    "        \n",
    "        self.layers = [self.conv1, self.bn1, self.conv2, self.bn2, self.conv3, self.bn3]\n",
    "        \n",
    "        self.input_ = tf.placeholder(tf.float32, shape=(1, 224, 224, num_input_channels))\n",
    "        self.output = self.forward(self.input_)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # main branch\n",
    "        FX = self.conv1.forward(X)\n",
    "        FX = self.bn1.forward(FX)\n",
    "        FX = self.f(FX)\n",
    "        FX = self.conv2.forward(FX)\n",
    "        FX = self.bn2.forward(FX)\n",
    "        FX = self.f(FX)\n",
    "        FX = self.conv3.forward(FX)\n",
    "        FX = self.bn3.forward(FX)\n",
    "        \n",
    "        return self.f(FX + X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert(self.session is not None)\n",
    "        return self.session.run(self.output, feed_dict={self.input_: X})\n",
    "    \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        self.conv1.session = session\n",
    "        self.bn1.session = session\n",
    "        self.conv2.session = session\n",
    "        self.bn2.session = session\n",
    "        self.conv3.session = session\n",
    "        self.bn3.session = session\n",
    "    \n",
    "    def copyFromKerasLayers(self, layers):\n",
    "        self.conv1.copyFromKerasLayers(layers[0])\n",
    "        self.bn1.copyFromKerasLayers(layers[1])\n",
    "        self.conv2.copyFromKerasLayers(layers[3])\n",
    "        self.bn2.copyFromKerasLayers(layers[4])\n",
    "        self.conv3.copyFromKerasLayers(layers[6])\n",
    "        self.bn3.copyFromKerasLayers(layers[7])\n",
    "    \n",
    "         \n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.get_params()\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ReLUlayer:\n",
    "    def forward(self, X):\n",
    "        return tf.nn.relu(X)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return tf.nn.max_pool(X, ksize=[1, self.dim, self.dim, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    def get_params(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePoolLayer:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return tf.nn.avg_pool(X, ksize=[1, self.dim, self.dim, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    def get_params(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroPaddingLayer:\n",
    "    def forward(self, X):\n",
    "        return tf.pad(X, paddings = tf.constant([[0, 0], [3, 3], [3, 3], [0, 0]]))\n",
    "        \n",
    "    def get_params(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, X):\n",
    "        n, w, h, c = X.get_shape().as_list()\n",
    "        return tf.reshape(X, [-1, w*h*c])\n",
    "    \n",
    "    def get_params(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.W = new_weights([input_size, output_size])\n",
    "        self.b = new_biases(output_size)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        m = tf.reduce_max(x, 1)\n",
    "        x -= m\n",
    "        e = tf.exp(x)\n",
    "        return e / tf.reduce_sum(e, -1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.softmax(tf.matmul(X, self.W))\n",
    "    \n",
    "    def get_params(self):\n",
    "        return [self.W]\n",
    "    \n",
    "    def copyFromKerasLayers(self, layer):\n",
    "        W, b = layer.get_weights()\n",
    "        op1 = self.W.assign(W)\n",
    "        op2 = self.b.assign(b)\n",
    "        self.session.run((op1, op2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialResNet:\n",
    "    def __init__(self):\n",
    "        self.layers = [ZeroPaddingLayer(),\n",
    "                       ConvLayer(filter_size=7, num_input_channels=3, num_filters=64, stride=2, padding='VALID'),\n",
    "                      BatchNormLayer(64), \n",
    "                      ReLUlayer(),\n",
    "                      MaxPoolLayer(dim = 3),\n",
    "                      ConvBlock(num_input_channels=64, feature_map_sizes=[64, 64, 256], stride=1),\n",
    "                      IdentityBlock(num_input_channels=256, feature_map_sizes=[64, 64, 256]), \n",
    "                      IdentityBlock(num_input_channels=256, feature_map_sizes=[64, 64, 256]), \n",
    "                      ConvBlock(num_input_channels=256, feature_map_sizes=[128, 128, 512]),\n",
    "                      IdentityBlock(num_input_channels=512, feature_map_sizes=[128, 128, 512]), \n",
    "                      IdentityBlock(num_input_channels=512, feature_map_sizes=[128, 128, 512]),\n",
    "                      IdentityBlock(num_input_channels=512, feature_map_sizes=[128, 128, 512]), \n",
    "                      ConvBlock(num_input_channels=512, feature_map_sizes=[256, 256, 1024]),\n",
    "                      IdentityBlock(num_input_channels=1024, feature_map_sizes=[256, 256, 1024]), \n",
    "                      IdentityBlock(num_input_channels=1024, feature_map_sizes=[256, 256, 1024]),\n",
    "                      IdentityBlock(num_input_channels=1024, feature_map_sizes=[256, 256, 1024]),\n",
    "                      IdentityBlock(num_input_channels=1024, feature_map_sizes=[256, 256, 1024]),\n",
    "                      IdentityBlock(num_input_channels=1024, feature_map_sizes=[256, 256, 1024]), \n",
    "                      ConvBlock(num_input_channels=1024, feature_map_sizes=[512, 512, 2048]),\n",
    "                      IdentityBlock(num_input_channels=2048, feature_map_sizes=[512, 512, 2048]),\n",
    "                      IdentityBlock(num_input_channels=2048, feature_map_sizes=[512, 512, 2048]),\n",
    "                      AveragePoolLayer(dim = 7),\n",
    "                      Flatten(),\n",
    "                      DenseLayer(2048, 1000)]\n",
    "   \n",
    "        self.input_ = tf.placeholder(tf.float32, shape = (None, 224, 224, 3))\n",
    "        self.output = self.forward(self.input_)\n",
    "    \n",
    "    def copyFromKerasLayers(self, layers):\n",
    "        self.layers[1].copyFromKerasLayers(layers[2])\n",
    "        self.layers[2].copyFromKerasLayers(layers[3])\n",
    "        self.layers[5].copyFromKerasLayers(layers[6:18])\n",
    "        self.layers[6].copyFromKerasLayers(layers[18:28])\n",
    "        self.layers[7].copyFromKerasLayers(layers[28:38])\n",
    "        self.layers[8].copyFromKerasLayers(layers[38:50])\n",
    "        self.layers[9].copyFromKerasLayers(layers[50:60])\n",
    "        self.layers[10].copyFromKerasLayers(layers[60:70])\n",
    "        self.layers[11].copyFromKerasLayers(layers[70:80])\n",
    "        self.layers[12].copyFromKerasLayers(layers[80:92])\n",
    "        self.layers[13].copyFromKerasLayers(layers[92:102])\n",
    "        self.layers[14].copyFromKerasLayers(layers[102:112])\n",
    "        self.layers[15].copyFromKerasLayers(layers[112:122])\n",
    "        self.layers[16].copyFromKerasLayers(layers[122:132])\n",
    "        self.layers[17].copyFromKerasLayers(layers[132:142])\n",
    "        self.layers[18].copyFromKerasLayers(layers[142:154])\n",
    "        self.layers[19].copyFromKerasLayers(layers[154:164])\n",
    "        self.layers[20].copyFromKerasLayers(layers[164:174])\n",
    "        self.layers[23].copyFromKerasLayers(layers[176])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert(self.session is not None)\n",
    "        return self.session.run(self.output, feed_dict={self.input_: X})\n",
    "    \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        self.layers[1].session = session\n",
    "        self.layers[2].session = session\n",
    "        self.layers[5].set_session(session)\n",
    "        self.layers[6].set_session(session)\n",
    "        self.layers[7].set_session(session)\n",
    "        self.layers[8].set_session(session)\n",
    "        self.layers[9].set_session(session)\n",
    "        self.layers[10].set_session(session)\n",
    "        self.layers[11].set_session(session)\n",
    "        self.layers[12].set_session(session)\n",
    "        self.layers[13].set_session(session)\n",
    "        self.layers[14].set_session(session)\n",
    "        self.layers[15].set_session(session)\n",
    "        self.layers[16].set_session(session)\n",
    "        self.layers[17].set_session(session)\n",
    "        self.layers[18].set_session(session)\n",
    "        self.layers[19].set_session(session)\n",
    "        self.layers[20].set_session(session)\n",
    "        self.layers[23].session = session\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.get_params()\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "partial_model = Model(input=resnet.input, output=resnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_partial_resnet = PartialResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.random((1, 224, 224, 3))\n",
    "keras_output = partial_model.predict(X)\n",
    "keras_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.variables_initializer(my_partial_resnet.get_params())\n",
    "session = keras.backend.get_session()\n",
    "my_partial_resnet.set_session(session)\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_output = my_partial_resnet.predict(X)\n",
    "my_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_partial_resnet.copyFromKerasLayers(partial_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0064948834"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = my_partial_resnet.predict(X)\n",
    "diff = np.abs(output - keras_output).sum()\n",
    "diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
